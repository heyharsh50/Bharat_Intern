{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d79dfb-6b71-4980-88ac-5366c24e34d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HARSH\n",
      "[nltk_data]     RAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\HARSH\n",
      "[nltk_data]     RAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\HARSH\n",
      "[nltk_data]     RAJ\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Keywords:\n",
      "science\n",
      "year\n",
      "source\n",
      "cloud\n",
      "analysis\n",
      "data\n",
      "spark\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # BHARAT INTERN ARTIFICIAL INTELLIGENCE INTERSHIP\n",
    "\n",
    "# # TASK 1: RESUME PARSER\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# ## Download NLTK resources \n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# ## Load the resume and job description text\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "resume_text = \"\"\"\n",
    "[WISFLUX TECHLABS. (80+ employee software as a service based startup) Jaipur, Raj\n",
    "Software Engineer Intern Mar 2022 – July 2022\n",
    "▪︎ Contributed to a React based project using front-end and worked on UI content for the application.\n",
    "▪︎ Aggregated unstructured data from 20+ sources to build the user manual of a new product.\n",
    "MICROSOFT- FUTURE READY TALENT (Virtual Internship by AICTE) Remote\n",
    "Software Engineer Intern Aug 2022 – 2022\n",
    "▪︎ Deployed project responsive website with HTML, CSS, Javascript & Bootstrap on Azure Cloud, Microsoft Service Link\n",
    "THE SPARKS FOUNDATION (Singapore based internship platform) Remote\n",
    "1. Android Development Intern. Sept 2022 —Oct 2022\n",
    "▪︎ Constructed basic application for social media Link\n",
    "2. Data Science Intern\n",
    "▪︎ Developed Data Analysis of Business data analytics on a Sample Store as Business perspective.Link\n",
    "GOLDMAN SACHS VIRTUAL INTERNSHIP - by FORAGE. Aug 2022– Sep 2022\n",
    "▪︎Completed virtual internship by in domain of cybersecurity :Cryptography, Password Cracking, password best practices\n",
    "WORDPRESS DEVELOPER (Ayushi George) Freelance\n",
    "▪︎ Constructed WordPress for over 2 years with 1500+ views and 22 followers and reach of 2000.\n",
    "▪︎ Delivered a site for clients service startup on the PreMarital advice platform.\n",
    "AR CREATOR (Augment Reality based filters developer by Meta's SparkAR) Freelance\n",
    "▪︎ Deployed AR based filters on official handles of JECRC College page for Renaissance (Annual Techno-Cultural Fest) and\n",
    "Freshers Party and MUN official filter.\n",
    "▪︎ Selected as Official Campus Representative for Meta's SparkAR training campaign, made AR Game as Filter\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "job_description = \"\"\"\n",
    "[0-3 years work experience Proficiency in Python, Spark, SQLDegree in data science, statistics, engineering, applied mathematics, operations research, information sciences, or another biological/physical science. Strength in code documentation Proficiency in Git and code versioning tools (Gitlab) Proficiency in Atlassian Suite such as JIRA and Confluence. Familiarity with cloud computing (AWS, Goolge Cloud preferred)Knowledge of statistics and machine learning (Computer Science/IT with good knowledge of Statistics)/ Analytics/ Data Science. Proficient in Python or R and other open source tools Relevant work experience of 0 to 4 years Intellectual curiosity and persistence to find answers to questions Eager to continuously learn and adapt to changing technologies and tools. Solid understanding of Statistics. Good aptitude for data analysis. Familiar with contemporary database systems]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ## Tokenize and preprocess the resume text\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "resume_tokens = word_tokenize(resume_text)\n",
    "resume_tokens = [token.lower() for token in resume_tokens if token.isalpha()]\n",
    "resume_tokens = [token for token in resume_tokens if token not in stopwords.words('english')]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "resume_tokens = [lemmatizer.lemmatize(token) for token in resume_tokens]\n",
    "\n",
    "\n",
    "# ## Tokenize and preprocess the job description text\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "job_tokens = word_tokenize(job_description)\n",
    "job_tokens = [token.lower() for token in job_tokens if token.isalpha()]\n",
    "job_tokens = [token for token in job_tokens if token not in stopwords.words('english')]\n",
    "job_tokens = [lemmatizer.lemmatize(token) for token in job_tokens]\n",
    "\n",
    "\n",
    "# ## Compare the tokens and find the matching keywords\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "matching_keywords = set(resume_tokens) & set(job_tokens)\n",
    "\n",
    "\n",
    "# ## Print the matching keywords\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "print(\"Matching Keywords:\")\n",
    "for keyword in matching_keywords:\n",
    "    print(keyword)\n",
    "\n",
    "\n",
    "#Thank_You "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d9007-6473-4138-b376-0fdc8f5849ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
